{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Recognizing hand-written digits\n",
    "\n",
    "This example shows how scikit-learn can be used to recognize images of\n",
    "hand-written digits, from 0-9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits dataset\n",
    "\n",
    "The digits dataset consists of 8x8\n",
    "pixel images of digits. The ``images`` attribute of the dataset stores\n",
    "8x8 arrays of grayscale values for each image. We will use these arrays to\n",
    "visualize the first 4 images. The ``target`` attribute of the dataset stores\n",
    "the digit each image represents and this is included in the title of the 4\n",
    "plots below.\n",
    "\n",
    "Note: if we were working from image files (e.g., 'png' files), we would load\n",
    "them using :func:`matplotlib.pyplot.imread`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Training: %i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "To apply a classifier on this data, we need to flatten the images, turning\n",
    "each 2-D array of grayscale values from shape ``(8, 8)`` into shape\n",
    "``(64,)``. Subsequently, the entire dataset will be of shape\n",
    "``(n_samples, n_features)``, where ``n_samples`` is the number of images and\n",
    "``n_features`` is the total number of pixels in each image.\n",
    "\n",
    "We can then split the data into train and test subsets and fit a support\n",
    "vector classifier on the train samples. The fitted classifier can\n",
    "subsequently be used to predict the value of the digit for the samples\n",
    "in the test subset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False\n",
    ")\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the value of the digit on the test subset\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we visualize the first 4 test samples and show their predicted\n",
    "digit value in the title.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, prediction in zip(axes, X_test, predicted):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(8, 8)\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":func:`~sklearn.metrics.classification_report` builds a text report showing\n",
    "the main classification metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Classification report for classifier {clf}:\\n\"\n",
    "    f\"{metrics.classification_report(y_test, predicted)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot a `confusion matrix <confusion_matrix>` of the\n",
    "true digit values and the predicted digit values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predicted)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
